{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons travailler sur des données médicales servant a prédire si les une patiente est atteinte du cancer du sein (Si la tumeur est bénigne ou maligne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Téléchargement des données et nettoyage (toutes les valeurs nulles sont retirées)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557\n"
     ]
    }
   ],
   "source": [
    "file = open(\"data.csv\",\"r\")\n",
    "Provdata= list(csv.reader(file, delimiter=\",\"))\n",
    "file.close()\n",
    "#print(data)\n",
    "data=[]\n",
    "data.append(Provdata[0])\n",
    "\n",
    "counter=0\n",
    "nulldata=0\n",
    "for e in range(1,len(Provdata)):\n",
    "    nulldata=0\n",
    "    for i in range(2,len(Provdata[e])):\n",
    "        if(float(Provdata[e][i])==0):\n",
    "            #print(\"ligne \",e,\" colonne \",i)\n",
    "            #print(data[e])\n",
    "            #data.remove(data[e])\n",
    "            nulldata=1\n",
    "    if(nulldata==0):\n",
    "        data.append(Provdata[e])\n",
    "    counter+=1\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce data set les valeurs sont M pour malignes et B pour Bénignes on va donc les ramener a des valeurs numérique 0 et 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(data)):\n",
    "    if(data[i][1]=='M'):\n",
    "        data[i][1]=float(1)\n",
    "    else:\n",
    "        data[i][1]=float(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le chargement des données du fichier csv nous donne des valeurs en String nous devons donc ramener ces valeurs a des valeurs numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(data)):\n",
    "    for e in range(0,len(data[i])):\n",
    "        data[i][e]=float(data[i][e])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On passe maintenant notre dataset en DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rowData=data[1:]\n",
    "labels=data[0]\n",
    "type(labels)\n",
    "labels=labels[:-1]\n",
    "labels\n",
    "\n",
    "\n",
    "\n",
    "data=pd.DataFrame(rowData)\n",
    "data.columns=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>845636.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>...</td>\n",
       "      <td>19.19</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84610002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.78</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>...</td>\n",
       "      <td>20.42</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>846226.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.17</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.3639</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>846381.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.85</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>...</td>\n",
       "      <td>16.84</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84667401.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.73</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>...</td>\n",
       "      <td>15.03</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84799002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.54</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.07364</td>\n",
       "      <td>...</td>\n",
       "      <td>17.46</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>848406.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.68</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.05259</td>\n",
       "      <td>...</td>\n",
       "      <td>19.07</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84862001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.13</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.4233</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>849014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.81</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.09498</td>\n",
       "      <td>...</td>\n",
       "      <td>27.32</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8510426.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.54</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.04781</td>\n",
       "      <td>...</td>\n",
       "      <td>15.11</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0     842302.0        1.0        17.99         10.38          122.80   \n",
       "1     842517.0        1.0        20.57         17.77          132.90   \n",
       "2   84300903.0        1.0        19.69         21.25          130.00   \n",
       "3   84348301.0        1.0        11.42         20.38           77.58   \n",
       "4   84358402.0        1.0        20.29         14.34          135.10   \n",
       "5     843786.0        1.0        12.45         15.70           82.57   \n",
       "6     844359.0        1.0        18.25         19.98          119.60   \n",
       "7   84458202.0        1.0        13.71         20.83           90.20   \n",
       "8     844981.0        1.0        13.00         21.82           87.50   \n",
       "9   84501001.0        1.0        12.46         24.04           83.97   \n",
       "10    845636.0        1.0        16.02         23.24          102.70   \n",
       "11  84610002.0        1.0        15.78         17.89          103.60   \n",
       "12    846226.0        1.0        19.17         24.80          132.40   \n",
       "13    846381.0        1.0        15.85         23.95          103.70   \n",
       "14  84667401.0        1.0        13.73         22.61           93.60   \n",
       "15  84799002.0        1.0        14.54         27.54           96.73   \n",
       "16    848406.0        1.0        14.68         20.13           94.74   \n",
       "17  84862001.0        1.0        16.13         20.68          108.10   \n",
       "18    849014.0        1.0        19.81         22.15          130.00   \n",
       "19   8510426.0        0.0        13.54         14.36           87.46   \n",
       "\n",
       "    area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0      1001.0          0.11840           0.27760         0.30010   \n",
       "1      1326.0          0.08474           0.07864         0.08690   \n",
       "2      1203.0          0.10960           0.15990         0.19740   \n",
       "3       386.1          0.14250           0.28390         0.24140   \n",
       "4      1297.0          0.10030           0.13280         0.19800   \n",
       "5       477.1          0.12780           0.17000         0.15780   \n",
       "6      1040.0          0.09463           0.10900         0.11270   \n",
       "7       577.9          0.11890           0.16450         0.09366   \n",
       "8       519.8          0.12730           0.19320         0.18590   \n",
       "9       475.9          0.11860           0.23960         0.22730   \n",
       "10      797.8          0.08206           0.06669         0.03299   \n",
       "11      781.0          0.09710           0.12920         0.09954   \n",
       "12     1123.0          0.09740           0.24580         0.20650   \n",
       "13      782.7          0.08401           0.10020         0.09938   \n",
       "14      578.3          0.11310           0.22930         0.21280   \n",
       "15      658.8          0.11390           0.15950         0.16390   \n",
       "16      684.5          0.09867           0.07200         0.07395   \n",
       "17      798.8          0.11700           0.20220         0.17220   \n",
       "18     1260.0          0.09831           0.10270         0.14790   \n",
       "19      566.3          0.09779           0.08129         0.06664   \n",
       "\n",
       "    concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0               0.14710  ...         25.38          17.33           184.60   \n",
       "1               0.07017  ...         24.99          23.41           158.80   \n",
       "2               0.12790  ...         23.57          25.53           152.50   \n",
       "3               0.10520  ...         14.91          26.50            98.87   \n",
       "4               0.10430  ...         22.54          16.67           152.20   \n",
       "5               0.08089  ...         15.47          23.75           103.40   \n",
       "6               0.07400  ...         22.88          27.66           153.20   \n",
       "7               0.05985  ...         17.06          28.14           110.60   \n",
       "8               0.09353  ...         15.49          30.73           106.20   \n",
       "9               0.08543  ...         15.09          40.68            97.65   \n",
       "10              0.03323  ...         19.19          33.88           123.80   \n",
       "11              0.06606  ...         20.42          27.28           136.50   \n",
       "12              0.11180  ...         20.96          29.94           151.70   \n",
       "13              0.05364  ...         16.84          27.66           112.00   \n",
       "14              0.08025  ...         15.03          32.01           108.80   \n",
       "15              0.07364  ...         17.46          37.13           124.10   \n",
       "16              0.05259  ...         19.07          30.88           123.40   \n",
       "17              0.10280  ...         20.96          31.48           136.80   \n",
       "18              0.09498  ...         27.32          30.88           186.80   \n",
       "19              0.04781  ...         15.11          19.26            99.70   \n",
       "\n",
       "    area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       2019.0            0.1622             0.6656           0.7119   \n",
       "1       1956.0            0.1238             0.1866           0.2416   \n",
       "2       1709.0            0.1444             0.4245           0.4504   \n",
       "3        567.7            0.2098             0.8663           0.6869   \n",
       "4       1575.0            0.1374             0.2050           0.4000   \n",
       "5        741.6            0.1791             0.5249           0.5355   \n",
       "6       1606.0            0.1442             0.2576           0.3784   \n",
       "7        897.0            0.1654             0.3682           0.2678   \n",
       "8        739.3            0.1703             0.5401           0.5390   \n",
       "9        711.4            0.1853             1.0580           1.1050   \n",
       "10      1150.0            0.1181             0.1551           0.1459   \n",
       "11      1299.0            0.1396             0.5609           0.3965   \n",
       "12      1332.0            0.1037             0.3903           0.3639   \n",
       "13       876.5            0.1131             0.1924           0.2322   \n",
       "14       697.7            0.1651             0.7725           0.6943   \n",
       "15       943.2            0.1678             0.6577           0.7026   \n",
       "16      1138.0            0.1464             0.1871           0.2914   \n",
       "17      1315.0            0.1789             0.4233           0.4784   \n",
       "18      2398.0            0.1512             0.3150           0.5372   \n",
       "19       711.2            0.1440             0.1773           0.2390   \n",
       "\n",
       "    concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.26540          0.4601                  0.11890  \n",
       "1                0.18600          0.2750                  0.08902  \n",
       "2                0.24300          0.3613                  0.08758  \n",
       "3                0.25750          0.6638                  0.17300  \n",
       "4                0.16250          0.2364                  0.07678  \n",
       "5                0.17410          0.3985                  0.12440  \n",
       "6                0.19320          0.3063                  0.08368  \n",
       "7                0.15560          0.3196                  0.11510  \n",
       "8                0.20600          0.4378                  0.10720  \n",
       "9                0.22100          0.4366                  0.20750  \n",
       "10               0.09975          0.2948                  0.08452  \n",
       "11               0.18100          0.3792                  0.10480  \n",
       "12               0.17670          0.3176                  0.10230  \n",
       "13               0.11190          0.2809                  0.06287  \n",
       "14               0.22080          0.3596                  0.14310  \n",
       "15               0.17120          0.4218                  0.13410  \n",
       "16               0.16090          0.3029                  0.08216  \n",
       "17               0.20730          0.3706                  0.11420  \n",
       "18               0.23880          0.2768                  0.07615  \n",
       "19               0.12880          0.2977                  0.07259  \n",
       "\n",
       "[20 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retire la première colonne car elle correspond aux identifiants des patients et pourrait ainsi fausser les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>...</td>\n",
       "      <td>19.19</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.78</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>...</td>\n",
       "      <td>20.42</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.17</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.3639</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.85</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>...</td>\n",
       "      <td>16.84</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.73</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>15.03</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.54</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.07364</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>...</td>\n",
       "      <td>17.46</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.68</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.05259</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>...</td>\n",
       "      <td>19.07</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.13</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.4233</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.81</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.09498</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>...</td>\n",
       "      <td>27.32</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.54</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.04781</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>...</td>\n",
       "      <td>15.11</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         1.0        17.99         10.38          122.80     1001.0   \n",
       "1         1.0        20.57         17.77          132.90     1326.0   \n",
       "2         1.0        19.69         21.25          130.00     1203.0   \n",
       "3         1.0        11.42         20.38           77.58      386.1   \n",
       "4         1.0        20.29         14.34          135.10     1297.0   \n",
       "5         1.0        12.45         15.70           82.57      477.1   \n",
       "6         1.0        18.25         19.98          119.60     1040.0   \n",
       "7         1.0        13.71         20.83           90.20      577.9   \n",
       "8         1.0        13.00         21.82           87.50      519.8   \n",
       "9         1.0        12.46         24.04           83.97      475.9   \n",
       "10        1.0        16.02         23.24          102.70      797.8   \n",
       "11        1.0        15.78         17.89          103.60      781.0   \n",
       "12        1.0        19.17         24.80          132.40     1123.0   \n",
       "13        1.0        15.85         23.95          103.70      782.7   \n",
       "14        1.0        13.73         22.61           93.60      578.3   \n",
       "15        1.0        14.54         27.54           96.73      658.8   \n",
       "16        1.0        14.68         20.13           94.74      684.5   \n",
       "17        1.0        16.13         20.68          108.10      798.8   \n",
       "18        1.0        19.81         22.15          130.00     1260.0   \n",
       "19        0.0        13.54         14.36           87.46      566.3   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           0.11840           0.27760         0.30010              0.14710   \n",
       "1           0.08474           0.07864         0.08690              0.07017   \n",
       "2           0.10960           0.15990         0.19740              0.12790   \n",
       "3           0.14250           0.28390         0.24140              0.10520   \n",
       "4           0.10030           0.13280         0.19800              0.10430   \n",
       "5           0.12780           0.17000         0.15780              0.08089   \n",
       "6           0.09463           0.10900         0.11270              0.07400   \n",
       "7           0.11890           0.16450         0.09366              0.05985   \n",
       "8           0.12730           0.19320         0.18590              0.09353   \n",
       "9           0.11860           0.23960         0.22730              0.08543   \n",
       "10          0.08206           0.06669         0.03299              0.03323   \n",
       "11          0.09710           0.12920         0.09954              0.06606   \n",
       "12          0.09740           0.24580         0.20650              0.11180   \n",
       "13          0.08401           0.10020         0.09938              0.05364   \n",
       "14          0.11310           0.22930         0.21280              0.08025   \n",
       "15          0.11390           0.15950         0.16390              0.07364   \n",
       "16          0.09867           0.07200         0.07395              0.05259   \n",
       "17          0.11700           0.20220         0.17220              0.10280   \n",
       "18          0.09831           0.10270         0.14790              0.09498   \n",
       "19          0.09779           0.08129         0.06664              0.04781   \n",
       "\n",
       "    symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0          0.2419  ...         25.38          17.33           184.60   \n",
       "1          0.1812  ...         24.99          23.41           158.80   \n",
       "2          0.2069  ...         23.57          25.53           152.50   \n",
       "3          0.2597  ...         14.91          26.50            98.87   \n",
       "4          0.1809  ...         22.54          16.67           152.20   \n",
       "5          0.2087  ...         15.47          23.75           103.40   \n",
       "6          0.1794  ...         22.88          27.66           153.20   \n",
       "7          0.2196  ...         17.06          28.14           110.60   \n",
       "8          0.2350  ...         15.49          30.73           106.20   \n",
       "9          0.2030  ...         15.09          40.68            97.65   \n",
       "10         0.1528  ...         19.19          33.88           123.80   \n",
       "11         0.1842  ...         20.42          27.28           136.50   \n",
       "12         0.2397  ...         20.96          29.94           151.70   \n",
       "13         0.1847  ...         16.84          27.66           112.00   \n",
       "14         0.2069  ...         15.03          32.01           108.80   \n",
       "15         0.2303  ...         17.46          37.13           124.10   \n",
       "16         0.1586  ...         19.07          30.88           123.40   \n",
       "17         0.2164  ...         20.96          31.48           136.80   \n",
       "18         0.1582  ...         27.32          30.88           186.80   \n",
       "19         0.1885  ...         15.11          19.26            99.70   \n",
       "\n",
       "    area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       2019.0            0.1622             0.6656           0.7119   \n",
       "1       1956.0            0.1238             0.1866           0.2416   \n",
       "2       1709.0            0.1444             0.4245           0.4504   \n",
       "3        567.7            0.2098             0.8663           0.6869   \n",
       "4       1575.0            0.1374             0.2050           0.4000   \n",
       "5        741.6            0.1791             0.5249           0.5355   \n",
       "6       1606.0            0.1442             0.2576           0.3784   \n",
       "7        897.0            0.1654             0.3682           0.2678   \n",
       "8        739.3            0.1703             0.5401           0.5390   \n",
       "9        711.4            0.1853             1.0580           1.1050   \n",
       "10      1150.0            0.1181             0.1551           0.1459   \n",
       "11      1299.0            0.1396             0.5609           0.3965   \n",
       "12      1332.0            0.1037             0.3903           0.3639   \n",
       "13       876.5            0.1131             0.1924           0.2322   \n",
       "14       697.7            0.1651             0.7725           0.6943   \n",
       "15       943.2            0.1678             0.6577           0.7026   \n",
       "16      1138.0            0.1464             0.1871           0.2914   \n",
       "17      1315.0            0.1789             0.4233           0.4784   \n",
       "18      2398.0            0.1512             0.3150           0.5372   \n",
       "19       711.2            0.1440             0.1773           0.2390   \n",
       "\n",
       "    concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.26540          0.4601                  0.11890  \n",
       "1                0.18600          0.2750                  0.08902  \n",
       "2                0.24300          0.3613                  0.08758  \n",
       "3                0.25750          0.6638                  0.17300  \n",
       "4                0.16250          0.2364                  0.07678  \n",
       "5                0.17410          0.3985                  0.12440  \n",
       "6                0.19320          0.3063                  0.08368  \n",
       "7                0.15560          0.3196                  0.11510  \n",
       "8                0.20600          0.4378                  0.10720  \n",
       "9                0.22100          0.4366                  0.20750  \n",
       "10               0.09975          0.2948                  0.08452  \n",
       "11               0.18100          0.3792                  0.10480  \n",
       "12               0.17670          0.3176                  0.10230  \n",
       "13               0.11190          0.2809                  0.06287  \n",
       "14               0.22080          0.3596                  0.14310  \n",
       "15               0.17120          0.4218                  0.13410  \n",
       "16               0.16090          0.3029                  0.08216  \n",
       "17               0.20730          0.3706                  0.11420  \n",
       "18               0.23880          0.2768                  0.07615  \n",
       "19               0.12880          0.2977                  0.07259  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaite maintenant avoir une idée de la forme de notre dataset on va donc regarder si il est équilibré ou non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 344\n"
     ]
    }
   ],
   "source": [
    "result=data['diagnosis']\n",
    "result=result.drop(0)\n",
    "\n",
    "cancer=0\n",
    "nocancer=0\n",
    "\n",
    "for i in range(1,550):\n",
    "    if(result[i]==0):\n",
    "        nocancer+=1\n",
    "    else:\n",
    "        cancer+=1\n",
    "print(cancer,nocancer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(result,bins=2,color='blue')\n",
    "plt.xticks([0,1],[\"pas cancer\",\"cancer\"])\n",
    "plt.show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque donc que notre data set n'est pas équilibré on va procéder a un sur échantillonage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ds = data.loc[data['diagnosis'] == 1]\n",
    "balanced_ds = pd.concat([data, filtered_ds])    # Sur-echantillonage de notre dataset\n",
    "balanced_ds.reset_index(drop=True, inplace=True)\n",
    "data=balanced_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 344\n"
     ]
    }
   ],
   "source": [
    "result=data['diagnosis']\n",
    "result=result.drop(0)\n",
    "\n",
    "cancer=0\n",
    "nocancer=0\n",
    "\n",
    "for i in range(1,550):\n",
    "    if(result[i]==0):\n",
    "        nocancer+=1\n",
    "    else:\n",
    "        cancer+=1\n",
    "print(cancer,nocancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(result,bins=2,color='blue')\n",
    "plt.xticks([0,1],[\"cancer\",\"pas de cancer\"])\n",
    "plt.show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant séparer nos données afin de pouvoir entraine nos différents modèles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=data['diagnosis']\n",
    "x=data.iloc[:,1:]\n",
    "X_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos données ne sont pas toutes a la même échelle on va donc les normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_normalise=scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_normlise=scaler.fit_transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sommes face a un projet de classification nous alloons pour le résoudre utiliser les algorithme DecisionTree RandomForest et KNeighbors\n",
    "\n",
    "Nous utilisons DecisionTree car : notre dataset n'est pas très gros et cet algorithme est performant sur ce type de dataSet, en revanche, il overfitt souvent c'est pourquoi nous utilisons RandomForest qui lui overfitt beaucoup moins\n",
    "\n",
    "Nous utilisons également kneighbors car il est efficace sur les petits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.948051948051948"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "forest=RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "forest.fit(X_train_normalise,y_train)\n",
    "\n",
    "ypredictionForest=forest.predict(X_test_normlise)\n",
    "accuracy_score(y_test,ypredictionForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.922077922077922"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree=DecisionTreeClassifier()\n",
    "\n",
    "tree.fit(X_train_normalise,y_train)\n",
    "y_prediciton_tree=tree.predict(X_test_normlise)\n",
    "accuracy_score(y_prediciton_tree,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961038961038961"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kvoisins = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "kvoisins.fit(X_train_normalise,y_train)\n",
    "y_prediction_voisin=kvoisins.predict(X_test_normlise)\n",
    "accuracy_score(y_prediction_voisin,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons des scores très élevés nous allons donc procéder a une crossvalidation pour vérifier si nos modèles n'overfitt pas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96103896 0.98701299 0.98051948 0.98039216 0.94117647]\n",
      "Average score: 0.9700280112044819\n",
      "Standard deviation: 0.016847493971733223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "x_normlise=scaler.fit_transform(x)\n",
    "\n",
    "scores =cross_val_score(tree,x_normlise,y,cv=5)\n",
    "\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Average score:', scores.mean())\n",
    "print('Standard deviation:', scores.std())\n",
    "scoretree=scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.95454545 0.99350649 0.98051948 0.9869281  0.97385621]\n",
      "Average score: 0.9778711484593838\n",
      "Standard deviation: 0.013369471685505004\n"
     ]
    }
   ],
   "source": [
    "scores =cross_val_score(forest,x_normlise,y,cv=5)\n",
    "\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Average score:', scores.mean())\n",
    "print('Standard deviation:', scores.std())\n",
    "scoreforest=scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.94805195 0.97402597 0.98051948 0.98039216 0.92156863]\n",
      "Average score: 0.9609116373822257\n",
      "Standard deviation: 0.023018201569423163\n"
     ]
    }
   ],
   "source": [
    "scores =cross_val_score(kvoisins,x_normlise,y,cv=5)\n",
    "\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Average score:', scores.mean())\n",
    "print('Standard deviation:', scores.std())\n",
    "scorevoisins=scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"RandomForest\", \"DecisionTree\", \"KVoisins\"]\n",
    "scores = [scoreforest, scoretree, scorevoisins]\n",
    "\n",
    "plt.bar(labels, scores, color='green')\n",
    "plt.title(\"Scores des modèles\")\n",
    "plt.xlabel(\"Modèles\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque donc avec les crossvalidations que en moyenne le meilleur algorithme sur notre dataset est RandomForest même si les scores restent très proches et que les modèles n'overfittent pas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va donc maintenant modifier les hyperparamètres\n",
    "\n",
    "On va donc utiliser un gridSearch avec un certains nombre de valeurs pour déterminer les meilleurs hyperparamètres\n",
    "Nous choisissons les paramètres maxdepth qui représe la profondeur max de chacun des arbres, n_estimators le nombre d'arbres et min_samples_split qui représente la valeur minimal requise pour diviser un noeud interne de l'arbre de decision en sous noeud. On considère que plus la valeur est grande plus la profondeur de l'arbre sera petite et aura moins de feuilles ce qui conduit a limiter l'overfitting\n",
    "\n",
    "les valeurs de min_samples souvent selectionnée par le GridSearch sont petites car RandomForest n'overfitt que très peu on chercher donc a augmenter la profondeur des arbres générés\n",
    "\n",
    "pour le nombre d'arbres plus il est faible plus la complexité diminue mais on risque de voir de l'overfitting\n",
    "\n",
    "la profondeur de l'arbre augmente l'accuracy mais peut entrainer de l'overfitting on chercher donc a avoir une profondeur moyenne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9653679653679653"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "forest=RandomForestClassifier()\n",
    "\n",
    "parametre = {\n",
    "    'n_estimators': [5, 10, 50, 100, 200],\n",
    "    'max_depth': [5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(forest, param_grid=parametre, cv=5)\n",
    "grid_search.fit(X_train_normalise, y_train)\n",
    "\n",
    "best_parameters=grid_search.best_params_\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres trouvés\n",
    "print(grid_search.best_params_)\n",
    "y_prediction_hyperparametre=grid_search.predict(X_test_normlise)\n",
    "accuracy_score(y_prediction_hyperparametre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96753247 0.99350649 0.98701299 0.98039216 0.9869281 ]\n",
      "Average score: 0.9830744418979712\n",
      "Standard deviation: 0.008808384353599055\n"
     ]
    }
   ],
   "source": [
    "scores =cross_val_score(grid_search,x_normlise,y,cv=5)\n",
    "\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Average score:', scores.mean())\n",
    "print('Standard deviation:', scores.std())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque donc que avec la selection des hyperparamètres l'accuracy moyenne augmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 96,   4],\n",
       "       [  4, 127]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_prediction_hyperparametre)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que certe les faux négatifs sont plus élevés que les faux positifs mais l'ordre de grandeur est tellement faible que ce résultat n'est pas exploitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=15)\n",
    "X_train_pca = pca.fit_transform(X_train_normalise)\n",
    "X_test_pca=pca.fit_transform(X_test_normlise)\n",
    "\n",
    "profondeur=best_parameters['max_depth']\n",
    "min=best_parameters['min_samples_split']\n",
    "nb=best_parameters['n_estimators']\n",
    "\n",
    "\n",
    "#kvoisinspca=KNeighborsClassifier(n_neighbors=nbkn,weights=weight,algorithm=algo)\n",
    "#kvoisinspca.fit(X_train_pca,y_train)\n",
    "\n",
    "forest=RandomForestClassifier(max_depth=profondeur,min_samples_split=min, n_estimators=nb)\n",
    "forest.fit(X_train_pca,y_train)\n",
    "#grid_search.fit(X_train_pca,y_train)\n",
    "y_prediction_forest_pca=forest.predict(X_test_pca)\n",
    "#y_prediction_kn_pca=grid_search.predict(X_test_pca)\n",
    "accuracy_score(y_prediction_forest_pca,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96753247 0.98051948 0.99350649 0.98039216 0.93464052]\n",
      "Average score: 0.9713182242594007\n",
      "Standard deviation: 0.020094299662411916\n"
     ]
    }
   ],
   "source": [
    "x_pca_normalise=pca.fit_transform(x_normlise)\n",
    "scores =cross_val_score(grid_search,x_pca_normalise,y,cv=5)\n",
    "\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Average score:', scores.mean())\n",
    "print('Standard deviation:', scores.std())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après le test avec les données en pca on remarque que l'accuracy n'augmente pas\n",
    "\n",
    "Soit les données sont très corrélées et donc on observe une perte d'information\n",
    "\n",
    "soit elles ont une structure non linéaire\n",
    "\n",
    "on va donc dans un premier temps déterminer la matrice de correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_correlation = data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                  1.000000\n",
       "radius_mean                0.701342\n",
       "texture_mean               0.443561\n",
       "perimeter_mean             0.713365\n",
       "area_mean                  0.661946\n",
       "smoothness_mean            0.365254\n",
       "compactness_mean           0.568930\n",
       "concavity_mean             0.667392\n",
       "concave points_mean        0.742797\n",
       "symmetry_mean              0.334455\n",
       "fractal_dimension_mean    -0.007413\n",
       "radius_se                  0.521418\n",
       "texture_se                 0.029234\n",
       "perimeter_se               0.507112\n",
       "area_se                    0.487661\n",
       "smoothness_se             -0.053716\n",
       "compactness_se             0.283213\n",
       "concavity_se               0.260772\n",
       "concave points_se          0.400917\n",
       "symmetry_se                0.014741\n",
       "fractal_dimension_se       0.084534\n",
       "radius_worst               0.743113\n",
       "texture_worst              0.476317\n",
       "perimeter_worst            0.749852\n",
       "area_worst                 0.681976\n",
       "smoothness_worst           0.419706\n",
       "compactness_worst          0.554764\n",
       "concavity_worst            0.645653\n",
       "concave points_worst       0.786987\n",
       "symmetry_worst             0.390263\n",
       "fractal_dimension_worst    0.306239\n",
       "Name: diagnosis, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrice_correlation['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 15\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "corr=0\n",
    "\n",
    "for e in matrice_correlation['diagnosis']:\n",
    "    if(e>0.5):\n",
    "        corr+=1\n",
    "    total+=1\n",
    "\n",
    "print(total,corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque donc que la moitié des features sont corrélées a plus de 50% (15/31) elle sont donc fortement corrélées ce qui pourrait expliquer une PCA qui affaiblit l'accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut donc conclure que le modèle randomforest apporche des 98% de prédiction ce qui est énorme cependant les modèles n'overfittent pas. \n",
    "\n",
    "Le dataset est petit ce qui peut donc expliquer un score très élevé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
